# -*- coding: utf-8 -*-
"""Semantic Image Segmentation on Martian Terrain with Tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/148Tw7MvkjiF96sjNI8DtXZO_Rah4YksB

**RESET**
"""

from google.colab import drive
drive.mount('/content/drive')

RESET = True
import os
import shutil

# path for all the training images
TRAINING_IMAGES_PATH = "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/msl/images/edr/"
# path for all the trianing labels (black and white masks)
TRAINING_MASKS_PATH = "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/msl/labels/train/"
# path for all the testing images
TESTING_IMAGES_PATH = "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/msl/images/edr/"
# path for all the testing labels (black and white masks)
TESTING_MASKS_PATH = "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/msl/labels/test/masked-gold-min1-100agree/"
## LIMIT FOR THE NUMBER OF IMAGES TO BE LOADED

LIMIT = 1500
VALIDATION = int(LIMIT * 0.75)

def move_training_masks_back_RESET(pathDir):
    for name in os.listdir(path="/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/train_masks/"):
        add_path = "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/train_masks/" + name
        print(add_path)
        shutil.move(add_path, pathDir)

    
def move_training_images_back_RESET(pathDir):
    for name in os.listdir(path="/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/train_images/"):
        add_path = "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/train_images/" + name
        shutil.move(add_path, pathDir)

def move_validation_masks_back_RESET(pathDir):
    for name in os.listdir(path="/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/validation_masks/"):
        add_path = "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/validation_masks/" + name
        shutil.move(add_path, pathDir)

    
def move_validation_images_back_RESET(pathDir):
    for name in os.listdir(path="/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/validation_images/"):
        add_path = "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/validation_images/" + name
        shutil.move(add_path, pathDir)

def reset():
  move_training_masks_back_RESET(TRAINING_MASKS_PATH)
  move_training_images_back_RESET(TRAINING_IMAGES_PATH)
  move_validation_masks_back_RESET(TRAINING_MASKS_PATH)
  move_validation_images_back_RESET(TRAINING_IMAGES_PATH)

if RESET:
  reset()

"""***Importing Libraries and Initial Setup***"""

import torch
import torch.nn as nn
import torchvision.transforms.functional as TF

import os
import cv2
import matplotlib.pyplot as plt
from PIL import Image

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms

import numpy as np

counter = 0

# list to store the names above 
TRAINING_IMAGES_NAMES = list()
VALIDATION_IMAGES_NAMES = list()

counter = 0
for name in os.listdir(path=TRAINING_MASKS_PATH):
  add = name[:-4]
  counter += 1
  if counter == LIMIT:
    break
  if counter < VALIDATION:
      TRAINING_IMAGES_NAMES.append(add)
  else:
      VALIDATION_IMAGES_NAMES.append(add)

len(VALIDATION_IMAGES_NAMES)

counter = 0

# list to store the names above
TESTING_IMAGES_NAMES = list()

for name in os.listdir(path=TESTING_MASKS_PATH):
  add = name[:-11]
  TESTING_IMAGES_NAMES.append(add)
  counter += 1
  if counter == LIMIT:
    break

TESTING_IMAGES_NAMES

"""**Preprocessing Methods**

"""

def show_histogram(img):
  plt.hist(img.ravel(),256,[0,256]); plt.show()

import torchvision.transforms as transforms

# -------------- TRAINING DATA -------------------------
training_images = list()
training_masks = list()


def get_training_masks(pathDir):
    for name in TRAINING_IMAGES_NAMES:
        img = Image.open(pathDir + name + '.png')
        training_masks.append(img)
      


def get_training_images(pathDir):
    for name in TRAINING_IMAGES_NAMES:
        img = Image.open(pathDir + name + '.JPG')
        training_images.append(img)


# ------------------- VALIDATION DATA ------------------------

validation_images = list()
validation_masks = list()

def get_validation_masks(pathDir):
    for name in VALIDATION_IMAGES_NAMES:
        img = Image.open(pathDir + name + '.png')
        validation_masks.append(img)
      

def get_validation_images(pathDir):
    for name in VALIDATION_IMAGES_NAMES:
        img = Image.open(pathDir + name + '.JPG')
        validation_images.append(img)



# ---------------- TESTING DATA ------------------
testing_images = list()
testing_masks = list()

def get_testing_masks(pathDir):
    for name in TESTING_IMAGES_NAMES:
        img = Image.open(pathDir + name + '_merged.png')
        testing_masks.append(img)

def get_testing_images(pathDir):
    for name in TESTING_IMAGES_NAMES:
        img = Image.open(pathDir + name + '.JPG')
        testing_images.append(img)

# get_training_masks(TRAINING_MASKS_PATH) 
# get_training_images(TRAINING_IMAGES_PATH)

# get_validation_masks(TRAINING_MASKS_PATH) 
# get_validation_images(TRAINING_IMAGES_PATH)

# get_testing_masks(TESTING_MASKS_PATH)
# get_testing_images(TESTING_IMAGES_PATH)

"""**MOVE DATA**

"""

import shutil
# ------------------ RUN ONLY ONCE -----------------------
def move_training_masks(pathDir):
    for name in TRAINING_IMAGES_NAMES:
        shutil.move(pathDir + name + '.png', "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/train_masks")

    
def move_training_images(pathDir):
    for name in TRAINING_IMAGES_NAMES:
        shutil.move(pathDir + name + '.JPG', "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/train_images")

def move_validation_masks(pathDir):
    for name in VALIDATION_IMAGES_NAMES:
        shutil.move(pathDir + name + '.png', "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/validation_masks")

    
def move_validation_images(pathDir):
    for name in VALIDATION_IMAGES_NAMES:
        shutil.move(pathDir + name + '.JPG', "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/validation_images")

move_training_masks(TRAINING_MASKS_PATH)
move_training_images(TRAINING_IMAGES_PATH)

move_validation_masks(TRAINING_MASKS_PATH)
move_validation_images(TRAINING_IMAGES_PATH)

TRAINING_DATA_IMAGES = "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/train_images/"
TRAINING_DATA_MASKS = "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/train_masks/"
VALIDATION_DATA_IMAGES = "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/validation_images/"
VALIDATION_DATA_MASKS = "/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/validation_masks/"

TRAINING_DATA = '/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/'
TEST_DATA = '"/content/drive/MyDrive/Energy Analytics/ai4mars-dataset-merged-0.1/DATASET/"'

def change_pixel_values(pix):
  zero_soil = 0
  one_br = 0
  two_sand = 0
  three_bigr = 0
  white = 0
  pixel_ttoal = 0

  BROWN_SOIL = [165, 42, 42] 
  BLUE_BR = [0, 0, 255]
  YELLOW_SAND = [255, 255, 0]
  RED_BIGR = [255, 0, 0]

  for y in range(img.shape[1]):
    for x in range(img.shape[0]):
      pixel_ttoal = pixel_ttoal + 1
      pixel = pix[x, y]
      if pixel[0] == 0:
        zero_soil = zero_soil + 1
        pix[x, y] = BROWN_SOIL
      elif pixel[0] == 1:
        one_br = one_br + 1
        pix[x, y] = BLUE_BR
      elif pixel[0] == 2:
        two_sand = two_sand + 1
        pix[x, y] = YELLOW_SAND
      elif pixel[0] == 3:
        three_bigr = three_bigr + 1
        pix[x, y] = RED_BIGR
      elif pixel[0] == 255:
        white = white + 1   


  # print("Soil BROWN [0]: " + str(zero_soil) + " pixels")
  # print("Bedrock BLUE [1]: " + str(one_br) + " pixels")
  # print("Sand YELLOW [2]: " + str(two_sand) + " pixels")
  # print("Bigrock RED [3]: " + str(three_bigr) + " pixels")
  # print("None [255]: " + str(white) + " pixels")
  # print("Total Pixels: " + str(pixel_ttoal) + " pixels")
  # print("Added Total: " + str(zero_soil + one_br + two_sand + three_bigr + white) + " pixels\n")
  return pix

def get_pixel(pix):
  for y in range(IMG_HEIGHT):
    for x in range(IMG_WIDTH):
      print("(" + str(x) + ", " + str(y) + "): " + str(pix[x,y]))
  print("\n")

def get_distribution(img):
  zero_soil = 0
  one_br = 0
  two_sand = 0
  three_bigr = 0
  white = 0
  pixel_ttoal = 0

  BROWN_SOIL = True #[0] 
  BLUE_BR = False #[0, 0, 255]
  YELLOW_SAND = False #[255, 255, 0]
  RED_BIGR = False #[255, 0, 0]

  for y in range(img.shape[1]):
    for x in range(img.shape[0]):
      pixel_ttoal = pixel_ttoal + 1
      pixel = img[x, y]
      if pixel[0] == 0:
        zero_soil = zero_soil + 1
      elif pixel[0] == 1:
        one_br = one_br + 1
      elif pixel[0] == 2:
        two_sand = two_sand + 1
      elif pixel[0] == 3:
        three_bigr = three_bigr + 1
      elif pixel[0] == 255:
        white = white + 1

      
      

  print("Soil BROWN [0]: " + str(zero_soil) + " pixels")
  print("Bedrock BLUE [1]: " + str(one_br) + " pixels")
  print("Sand YELLOW [2]: " + str(two_sand) + " pixels")
  print("Bigrock RED [3]: " + str(three_bigr) + " pixels")
  print("None [255]: " + str(white) + " pixels")
  print("Total Pixels: " + str(pixel_ttoal) + " pixels")
  print("Added Total: " + str(zero_soil + one_br + two_sand + three_bigr + white) + " pixels\n")
  return img

def display_img(img, cmap=None):
  fig = plt.figure(figsize=(5, 5))
  ax = fig.add_subplot(111)
  ax.imshow(img, cmap)

import random
import numpy as np
 
from tqdm import tqdm 

from skimage.io import imread, imshow
from skimage.transform import resize
import matplotlib.pyplot as plt

seed = 42
np.random.seed = seed

IMG_WIDTH = 128
IMG_HEIGHT = 128
IMG_CHANNELS = 3

TRAIN_PATH = TRAINING_DATA 
TEST_PATH = VALIDATION_DATA_IMAGES

train_ids = TRAINING_IMAGES_NAMES
test_ids = VALIDATION_IMAGES_NAMES

X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)
Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)

"""--- Start of the Model ----"""

from keras.utils.np_utils import normalize
import os
import glob
import cv2
import numpy as np
from matplotlib import pyplot as plt


#Resizing images, if needed
SIZE_X = 128 
SIZE_Y = 128
n_classes=5 #Number of classes for segmentation

#Capture training image info as a list
train_images = []
nonlist_train_images = []
ordered_train_images_names = []

counter = 0
for name in os.listdir(path=TRAINING_DATA_IMAGES):
    img = cv2.imread(TRAINING_DATA_IMAGES + name, 0) 
    img = cv2.resize(img, (SIZE_Y, SIZE_X))
    train_images.append(img)
    nonlist_train_images.append(img)
    ordered_train_images_names.append(name)
    print(counter)
    print(name) 
    counter = counter + 1


#Convert list to array for machine learning processing        
train_images = np.array(train_images)

#Capture mask/label info as a list
train_masks = [] 
original_train_masks = []
counter = 0
for name in ordered_train_images_names:
    img = cv2.imread(TRAINING_DATA_MASKS + name[:-4] + '.png')
    img = cv2.resize(img, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)
    original_train_masks.append(img.copy())
    change_pixel_values(img)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    train_masks.append(img)
    print(counter)
    print(name)
    counter = counter + 1
    
        
#Convert list to array for machine learning processing          
train_masks = np.array(train_masks)
original_train_masks = np.array(original_train_masks)

plt.imshow(train_images[3])

plt.imshow(original_train_masks[3])

plt.imshow(train_masks[3])

"""
Standard Unet
Model not compiled here, instead will be done externally to make it
easy to test various loss functions and optimizers. 
"""


from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda




################################################################
def multi_unet_model(n_classes=5, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):
#Build the model
    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand
    s = inputs

    #Contraction path
    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)
    c1 = Dropout(0.1)(c1)
    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)
    p1 = MaxPooling2D((2, 2))(c1)
    
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)
     
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)
    c3 = Dropout(0.2)(c3)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)
     
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)
    p4 = MaxPooling2D(pool_size=(2, 2))(c4)
     
    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)
    c5 = Dropout(0.3)(c5)
    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)
    
    #Expansive path 
    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)
     
    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = concatenate([u7, c3])
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)
     
    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = concatenate([u8, c2])
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)
    c8 = Dropout(0.1)(c8)
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)
     
    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)
    c9 = Dropout(0.1)(c9)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)
     
    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)
     
    model = Model(inputs=[inputs], outputs=[outputs])
    
    #NOTE: Compile the model in the main program to make it easy to test with various loss functions
    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    
    #model.summary()
    
    return model

train_masks.shape

#Encode labels... but multi dim array so need to flatten, encode and reshape
from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
n, h, w = train_masks.shape
train_masks_reshaped = train_masks.reshape(-1,1)
train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)
train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)

np.unique(train_masks_encoded_original_shape)

train_images = np.expand_dims(train_images, axis=3)
train_images = normalize(train_images, axis=1)

train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis=3)

#Create a subset of data for quick testing
#Picking 10% for testing and remaining for training
from sklearn.model_selection import train_test_split
X1, X_test, y1, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state = 0)

#Further split training data t a smaller subset for quick testing of models
X_train, X_do_not_use, y_train, y_do_not_use = train_test_split(X1, y1, test_size = 0.2, random_state = 0)

print("Class values in the dataset are ... ", np.unique(y_train))  # 0 is the background/few unlabeled 

from tensorflow.keras.utils import to_categorical
train_masks_cat = to_categorical(y_train, num_classes=n_classes)
y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))



test_masks_cat = to_categorical(y_test, num_classes=n_classes)
y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))



from sklearn.utils import class_weight
class_weights = class_weight.compute_class_weight(class_weight = 'balanced',
                                                 classes = np.unique(train_masks_reshaped_encoded),
                                                 y = train_masks_reshaped_encoded)
print("Class weights are...:", class_weights)


IMG_HEIGHT = X_train.shape[1]
IMG_WIDTH  = X_train.shape[2]
IMG_CHANNELS = X_train.shape[3]

def get_model():
    return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)

model = get_model()
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

#If starting with pre-trained weights. 
#model.load_weights('???.hdf5')

history = model.fit(X_train, y_train_cat, 
                    batch_size = 10, 
                    verbose=1, 
                    epochs=25, 
                    validation_data=(X_test, y_test_cat), 
                    #class_weight=class_weights,
                    shuffle=False)
                    


model.save('test.hdf5')
#model.save('sandstone_50_epochs_ca

#Evaluate the model
	# evaluate model
_, acc = model.evaluate(X_test, y_test_cat)
print("Accuracy is = ", (acc * 100.0), "%")


###
#plot the training and validation accuracy and loss at each epoch
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

#-------------------------------------

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']


plt.plot(epochs, acc, 'y', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Training and validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

model.load_weights('test.hdf5')  
#model.load_weights('sandstone_50_epochs_catXentropy_acc_with_weights.hdf5')  

#IOU
y_pred=model.predict(X_test)
y_pred_argmax=np.argmax(y_pred, axis=3)

#Using built in keras function
from keras.metrics import MeanIoU
n_classes = 5
IOU_keras = MeanIoU(num_classes=n_classes)  
IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)
print("Mean IoU =", IOU_keras.result().numpy())


#To calculate I0U for each class...
values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)
print(values)
class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0]+ values[2,0]+ values[3,0])
class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1]+ values[2,1]+ values[3,1])
class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2]+ values[1,2]+ values[3,2])
class4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])

print("IoU for class1 is: ", class1_IoU)
print("IoU for class2 is: ", class2_IoU)
print("IoU for class3 is: ", class3_IoU)
print("IoU for class4 is: ", class4_IoU)

plt.imshow(train_images[0, :,:,0], cmap='gray')
plt.imshow(train_masks[0], cmap='gray')

#Predict on a few images
model = get_model()
model.load_weights('test.hdf5')  
import random
def show_test_pred(index):
  test_img_number = index
  test_img = X_test[test_img_number]
  ground_truth=y_test[test_img_number]
  test_img_norm=test_img[:,:,0][:,:,None]
  test_img_input=np.expand_dims(test_img_norm, 0)
  prediction = (model.predict(test_img_input))
  predicted_img=np.argmax(prediction, axis=3)[0,:,:]


  plt.figure(figsize=(12, 8))
  plt.subplot(231)
  plt.title('Testing Image', cmap='gray')
  plt.imshow(test_img[:,:,0])
  plt.subplot(232)
  plt.title('Testing Label')
  plt.imshow(ground_truth[:,:,0], cmap='ocean')
  plt.subplot(233)
  plt.title('Prediction on test image')
  plt.imshow(predicted_img, cmap='ocean')
  plt.show()

for i in range(0, len(X_test)):
  show_test_pred(i)

np.unique(predicted_img)

X_test.shape

len(X_train)

#Predict on a few training images
model = get_model()
model.load_weights('test.hdf5')  
def get_train_preds(index):
  train_img_number = index
  train_img = X_train[train_img_number]
  ground_truth=y_train[train_img_number]
  train_img_norm=train_img[:,:,0][:,:,None]
  train_img_input=np.expand_dims(train_img_norm, 0)
  prediction = (model.predict(train_img_input))
  predicted_img=np.argmax(prediction, axis=3)[0,:,:]

  print("Index: " + str(train_img_number))


  plt.figure(figsize=(12, 8))
  plt.subplot(231)
  plt.title('Training Image')
  plt.imshow(train_img[:,:,0], cmap='gray')
  plt.subplot(232)
  plt.title('Training Label')
  plt.imshow(ground_truth[:,:,0], cmap='jet')
  plt.subplot(233)
  plt.title('Prediction on train image')
  plt.imshow(predicted_img, cmap='jet')
  plt.show()



for i in range(1, len(X_train)):
  get_train_preds(i)





"""Red - (255, 255, 255) 
Blue - (1, 1, 1)

"""

get_distribution(original_train_masks[376])

plt.imshow(original_train_masks[376])

!pip install pyinotify
!pip install patchify

len(str)